{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AidanJIC/Clasificaci-n-de-productos-en-supermercados-utilizando-visi-n-computacional/blob/main/Laboratorios/Pr%C3%A1ctica_PDSeI_01_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch"
      ],
      "metadata": {
        "id": "-sfd5y_LexZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalaciones"
      ],
      "metadata": {
        "id": "tQGP2l2Ee2zU"
      }
    },
    {
      "metadata": {
        "id": "PtKvmZx-WmUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d76c6c-dd69-4eb7-cb34-4bcfdf484bfe"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar dependencias"
      ],
      "metadata": {
        "id": "3dr3HMvje_kV"
      }
    },
    {
      "metadata": {
        "id": "bGU6NwlsXFSt"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir Hiperparámetros"
      ],
      "metadata": {
        "id": "RbUo8FmkfFB1"
      }
    },
    {
      "metadata": {
        "id": "_bNfVLRUYqZA"
      },
      "cell_type": "code",
      "source": [
        "input_size = 784\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "lr = 1e-3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descargando la base de datos mnist"
      ],
      "metadata": {
        "id": "DM48UlJ9gMOE"
      }
    },
    {
      "metadata": {
        "id": "lCsBCXMwbpH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf17b62-7e51-47bd-fd75-e5cd9a1c9ce1"
      },
      "cell_type": "code",
      "source": [
        "train_data = dsets.FashionMNIST(root = './data', train = True,\n",
        "                        transform = transforms.ToTensor(), download = True)\n",
        "\n",
        "test_data = dsets.FashionMNIST(root = './data', train = False,\n",
        "                       transform = transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:11<00:00, 2237979.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 202442.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3725074.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 24179481.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leyendo la data"
      ],
      "metadata": {
        "id": "WpMOKBJkhisv"
      }
    },
    {
      "metadata": {
        "id": "rfDPBdnYgfGp"
      },
      "cell_type": "code",
      "source": [
        "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
        "                                             batch_size = batch_size,\n",
        "                                             shuffle = True)\n",
        "\n",
        "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
        "                                      batch_size = batch_size,\n",
        "                                      shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definir modelo"
      ],
      "metadata": {
        "id": "jhaazXo-h9-v"
      }
    },
    {
      "metadata": {
        "id": "fL-YXTvghaz_"
      },
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.drop = nn.Dropout(0.2)\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.fc1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.drop(out)\n",
        "    out = self.fc2(out)\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instancia del modelo"
      ],
      "metadata": {
        "id": "uQdjiXCeiNiu"
      }
    },
    {
      "metadata": {
        "id": "-3EPEqbjjfAT"
      },
      "cell_type": "code",
      "source": [
        "net = Net(input_size, hidden_size, num_classes)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilación"
      ],
      "metadata": {
        "id": "QNgkx4xtipMA"
      }
    },
    {
      "metadata": {
        "id": "ePLIwvAFj2zH"
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenamiento"
      ],
      "metadata": {
        "id": "KD3x_O7si_zS"
      }
    },
    {
      "metadata": {
        "id": "u75Xa5VckuTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f193b404-a381-4774-e85e-c91304624af7"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_gen):\n",
        "    images = images.view(-1, 28*28).cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print('Epoca [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "              % (epoch + 1, num_epochs, i + 1, len(train_data) // batch_size, loss.item()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca [1/5], Step [100/600], Loss: 0.6858\n",
            "Epoca [1/5], Step [200/600], Loss: 0.4623\n",
            "Epoca [1/5], Step [300/600], Loss: 0.5077\n",
            "Epoca [1/5], Step [400/600], Loss: 0.5390\n",
            "Epoca [1/5], Step [500/600], Loss: 0.4710\n",
            "Epoca [1/5], Step [600/600], Loss: 0.4209\n",
            "Epoca [2/5], Step [100/600], Loss: 0.4241\n",
            "Epoca [2/5], Step [200/600], Loss: 0.3720\n",
            "Epoca [2/5], Step [300/600], Loss: 0.3053\n",
            "Epoca [2/5], Step [400/600], Loss: 0.2724\n",
            "Epoca [2/5], Step [500/600], Loss: 0.4052\n",
            "Epoca [2/5], Step [600/600], Loss: 0.5020\n",
            "Epoca [3/5], Step [100/600], Loss: 0.2904\n",
            "Epoca [3/5], Step [200/600], Loss: 0.4464\n",
            "Epoca [3/5], Step [300/600], Loss: 0.2642\n",
            "Epoca [3/5], Step [400/600], Loss: 0.4933\n",
            "Epoca [3/5], Step [500/600], Loss: 0.4052\n",
            "Epoca [3/5], Step [600/600], Loss: 0.3526\n",
            "Epoca [4/5], Step [100/600], Loss: 0.4071\n",
            "Epoca [4/5], Step [200/600], Loss: 0.3768\n",
            "Epoca [4/5], Step [300/600], Loss: 0.3226\n",
            "Epoca [4/5], Step [400/600], Loss: 0.2910\n",
            "Epoca [4/5], Step [500/600], Loss: 0.3905\n",
            "Epoca [4/5], Step [600/600], Loss: 0.2888\n",
            "Epoca [5/5], Step [100/600], Loss: 0.3352\n",
            "Epoca [5/5], Step [200/600], Loss: 0.3353\n",
            "Epoca [5/5], Step [300/600], Loss: 0.2938\n",
            "Epoca [5/5], Step [400/600], Loss: 0.2197\n",
            "Epoca [5/5], Step [500/600], Loss: 0.4774\n",
            "Epoca [5/5], Step [600/600], Loss: 0.3058\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DTPvMW5jHB9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41191187-57b4-45d2-af70-95dafd58719b"
      },
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for images, labels in test_gen:\n",
        "    images = images.view(-1, 28*28).cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    output = net(images)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += labels.size(0)\n",
        "\n",
        "print('Accuracy: %.3f %%' % (100 * correct / (total + 1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 86.041 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r1NojkXHle9d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}